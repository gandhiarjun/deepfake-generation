{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Face Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "automated-beads"
      },
      "source": [
        "import face_recognition\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import os\n",
        "import cv2\n",
        "import pathlib"
      ],
      "id": "automated-beads",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "later-landing"
      },
      "source": [
        "def extractImages(fileName):\n",
        "    print(fileName)\n",
        "    pathOut = str(pathlib.Path().absolute()) + \"/\" + fileName[0:-4] + \"/\"\n",
        "    if not os.path.exists(pathOut):\n",
        "        os.makedirs(pathOut)\n",
        "    print(pathOut)\n",
        "    count = 0\n",
        "    vidcap = cv2.VideoCapture(fileName)\n",
        "    success,image = vidcap.read()\n",
        "    success = True\n",
        "    while success:\n",
        "        # vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*1000))    # added this line\n",
        "        success,image = vidcap.read()\n",
        "\n",
        "        if success:\n",
        "            \n",
        "#             print ('Read a new frame: ', success)\n",
        "            frameName = pathOut + \"frame%d.jpg\" % count\n",
        "            if count % 700 == 0:\n",
        "                print(frameName)\n",
        "\n",
        "            cv2.imwrite(frameName, image)     # save frame as JPEG file\n",
        "            count = count + 1"
      ],
      "id": "later-landing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "smaller-cause",
        "outputId": "ed90d19a-994f-4522-f39a-748e0cb9d1c0"
      },
      "source": [
        "extractImages('Videos/JohnOliver1-cropped.mp4')"
      ],
      "id": "smaller-cause",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Videos/JohnOliver1-cropped.mp4\n",
            "/Users/arjunkumargandhi/Google Drive/Classes/CMSC472/Project/deepfake-generation/Videos/JohnOliver1-cropped/\n",
            "/Users/arjunkumargandhi/Google Drive/Classes/CMSC472/Project/deepfake-generation/Videos/JohnOliver1-cropped/frame0.jpg\n",
            "/Users/arjunkumargandhi/Google Drive/Classes/CMSC472/Project/deepfake-generation/Videos/JohnOliver1-cropped/frame700.jpg\n",
            "/Users/arjunkumargandhi/Google Drive/Classes/CMSC472/Project/deepfake-generation/Videos/JohnOliver1-cropped/frame1400.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reduced-porcelain"
      },
      "source": [
        "\"\"\"\n",
        "    Parameters: \n",
        "        - imageDir: the file path for the image directory extract the faces from\n",
        "        - face_encoded: the face encoder we want to compare to see if we have extracted the correct face\n",
        "\"\"\"\n",
        "def singleFaceExtracter(imageDir, face_encoder):\n",
        "    pathOut = str(pathlib.Path().absolute())+'/'+imageDir[:-1]+'-face-crop/'\n",
        "    if not os.path.exists(pathOut):\n",
        "        os.makedirs(pathOut)\n",
        "    print(pathOut)\n",
        "    count = 0\n",
        "    for filename in os.listdir(imageDir):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            image = face_recognition.load_image_file(imageDir+filename)\n",
        "            # makes sure there is only one face in the image\n",
        "            if len(face_recognition.face_locations(image)) == 1:\n",
        "                top, right, bottom, left = face_recognition.face_locations(image)[0]\n",
        "                cropped_face = image[top:bottom,left:right]\n",
        "                try:\n",
        "                  cropped_encoding = face_recognition.face_encodings(cropped_face)[0]\n",
        "                except IndexError as e:\n",
        "                  print(filename)\n",
        "                  continue\n",
        "                \n",
        "                # makes sure it is the face that was encoded\n",
        "                if(face_recognition.compare_faces([face_encoder], cropped_encoding))[0]:\n",
        "                    frameName = pathOut + filename[0:-4] + \"-face-cropped\" + \".jpg\"\n",
        "                    cropped_face = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB)\n",
        "                    cv2.imwrite(frameName, cropped_face)     # save cropped as JPEG file\n",
        "                    if(count % 700 == 0): print(filename[0:-4] + \"-face-cropped\" + \".jpg\")\n",
        "                    count += 1"
      ],
      "id": "reduced-porcelain",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "included-hospital",
        "outputId": "c32bde96-42f0-4289-ca5e-766d92f62118"
      },
      "source": [
        "image = face_recognition.load_image_file(\"./Faces/JohnOliver1.jpg\")\n",
        "oliver_encoding = face_recognition.face_encodings(image)[0]\n",
        "\n",
        "image2 = face_recognition.load_image_file(\"./Videos/JohnOliver1-cropped/frame103.jpg\")\n",
        "unknown_encoding = face_recognition.face_encodings(image2)[0]\n",
        "\n",
        "results = face_recognition.compare_faces([oliver_encoding], unknown_encoding)\n",
        "print(results)"
      ],
      "id": "included-hospital",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "standard-antenna",
        "outputId": "d85c99c2-2cff-4488-a7f0-857cfc2c1996"
      },
      "source": [
        "image = face_recognition.load_image_file(\"./Faces/JimmyFallon.jpg\")\n",
        "jimmy_encoding = face_recognition.face_encodings(image)[0]\n",
        "singleFaceExtracter('Faces/', jimmy_encoding)"
      ],
      "id": "standard-antenna",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/snippy/Documents/CS/CMSC472/Final Proj/deepfake-generation/Faces-face-crop/\n",
            "JimmyFallon-face-cropped.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fitting-letters"
      },
      "source": [
        ""
      ],
      "id": "fitting-letters",
      "execution_count": null,
      "outputs": []
    }
  ]
}